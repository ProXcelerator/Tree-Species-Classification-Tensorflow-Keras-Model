{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make sure we have a gpu to run this large amount of code on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do we have a gpu to run on\n",
    "tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0       2596      51      3                               258   \n",
       "1       2590      56      2                               212   \n",
       "2       2804     139      9                               268   \n",
       "3       2785     155     18                               242   \n",
       "4       2595      45      2                               153   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "1                              -6                              390   \n",
       "2                              65                             3180   \n",
       "3                             118                             3090   \n",
       "4                              -1                              391   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0            221             232            148   \n",
       "1            220             235            151   \n",
       "2            234             238            135   \n",
       "3            238             238            122   \n",
       "4            220             234            150   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
       "0                                6279  ...            0            0   \n",
       "1                                6225  ...            0            0   \n",
       "2                                6121  ...            0            0   \n",
       "3                                6211  ...            0            0   \n",
       "4                                6172  ...            0            0   \n",
       "\n",
       "   Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type39  Soil_Type40  class  \n",
       "0            0            0      5  \n",
       "1            0            0      5  \n",
       "2            0            0      2  \n",
       "3            0            0      2  \n",
       "4            0            0      5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cover_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Slope\n",
       "11    33824\n",
       "10    33812\n",
       "12    33217\n",
       "13    32419\n",
       "9     32049\n",
       "      ...  \n",
       "65        2\n",
       "58        1\n",
       "64        1\n",
       "63        1\n",
       "66        1\n",
       "Name: count, Length: 67, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the value counts and see if were dealing with 10 categorical values or thousands of continuous values \n",
    "df['class'].value_counts() # has 7 values represending the types of trees the data is looking at\n",
    "df['Horizontal_Distance_To_Hydrology'].value_counts() # from the 5 rows above it looks like it might be a small range but it contains a large range of values\n",
    "df['Slope'].value_counts()# from the 5 rows above it looks like it might be a small range but it contains a large range of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary defineing the type of tree with the number assosicated with it. \n",
    "class_dict = {'spruce': 1, 'lodgepole_pine' : 2, 'ponderosa_pine': 3, 'cottonwood_willow': 4, 'aspen': 5, 'douglas_fir': 6, 'krummholz': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 581012 entries, 0 to 581011\n",
      "Data columns (total 55 columns):\n",
      " #   Column                              Non-Null Count   Dtype\n",
      "---  ------                              --------------   -----\n",
      " 0   Elevation                           581012 non-null  int64\n",
      " 1   Aspect                              581012 non-null  int64\n",
      " 2   Slope                               581012 non-null  int64\n",
      " 3   Horizontal_Distance_To_Hydrology    581012 non-null  int64\n",
      " 4   Vertical_Distance_To_Hydrology      581012 non-null  int64\n",
      " 5   Horizontal_Distance_To_Roadways     581012 non-null  int64\n",
      " 6   Hillshade_9am                       581012 non-null  int64\n",
      " 7   Hillshade_Noon                      581012 non-null  int64\n",
      " 8   Hillshade_3pm                       581012 non-null  int64\n",
      " 9   Horizontal_Distance_To_Fire_Points  581012 non-null  int64\n",
      " 10  Wilderness_Area1                    581012 non-null  int64\n",
      " 11  Wilderness_Area2                    581012 non-null  int64\n",
      " 12  Wilderness_Area3                    581012 non-null  int64\n",
      " 13  Wilderness_Area4                    581012 non-null  int64\n",
      " 14  Soil_Type1                          581012 non-null  int64\n",
      " 15  Soil_Type2                          581012 non-null  int64\n",
      " 16  Soil_Type3                          581012 non-null  int64\n",
      " 17  Soil_Type4                          581012 non-null  int64\n",
      " 18  Soil_Type5                          581012 non-null  int64\n",
      " 19  Soil_Type6                          581012 non-null  int64\n",
      " 20  Soil_Type7                          581012 non-null  int64\n",
      " 21  Soil_Type8                          581012 non-null  int64\n",
      " 22  Soil_Type9                          581012 non-null  int64\n",
      " 23  Soil_Type10                         581012 non-null  int64\n",
      " 24  Soil_Type11                         581012 non-null  int64\n",
      " 25  Soil_Type12                         581012 non-null  int64\n",
      " 26  Soil_Type13                         581012 non-null  int64\n",
      " 27  Soil_Type14                         581012 non-null  int64\n",
      " 28  Soil_Type15                         581012 non-null  int64\n",
      " 29  Soil_Type16                         581012 non-null  int64\n",
      " 30  Soil_Type17                         581012 non-null  int64\n",
      " 31  Soil_Type18                         581012 non-null  int64\n",
      " 32  Soil_Type19                         581012 non-null  int64\n",
      " 33  Soil_Type20                         581012 non-null  int64\n",
      " 34  Soil_Type21                         581012 non-null  int64\n",
      " 35  Soil_Type22                         581012 non-null  int64\n",
      " 36  Soil_Type23                         581012 non-null  int64\n",
      " 37  Soil_Type24                         581012 non-null  int64\n",
      " 38  Soil_Type25                         581012 non-null  int64\n",
      " 39  Soil_Type26                         581012 non-null  int64\n",
      " 40  Soil_Type27                         581012 non-null  int64\n",
      " 41  Soil_Type28                         581012 non-null  int64\n",
      " 42  Soil_Type29                         581012 non-null  int64\n",
      " 43  Soil_Type30                         581012 non-null  int64\n",
      " 44  Soil_Type31                         581012 non-null  int64\n",
      " 45  Soil_Type32                         581012 non-null  int64\n",
      " 46  Soil_Type33                         581012 non-null  int64\n",
      " 47  Soil_Type34                         581012 non-null  int64\n",
      " 48  Soil_Type35                         581012 non-null  int64\n",
      " 49  Soil_Type36                         581012 non-null  int64\n",
      " 50  Soil_Type37                         581012 non-null  int64\n",
      " 51  Soil_Type38                         581012 non-null  int64\n",
      " 52  Soil_Type39                         581012 non-null  int64\n",
      " 53  Soil_Type40                         581012 non-null  int64\n",
      " 54  class                               581012 non-null  int64\n",
      "dtypes: int64(55)\n",
      "memory usage: 243.8 MB\n"
     ]
    }
   ],
   "source": [
    "# are their any columns that contain NaN values or are their any Dtypes that need to be changed? \n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "## What do we want to remove? \n",
    "We dont have NaN values in any rows and the dtypes look appropriate.  \n",
    "## Are their any biases in any columns of data? \n",
    "-This seems to be a hard question to answer in this dataset.   \n",
    "--Tree come from very specific climates and soil types so they can survive.   \n",
    "--One could say the soil types are biased to specific tree types or even a combination of some soil types.   \n",
    "--Soil types are apart of the tree in my opinion and need to stay. \n",
    "\n",
    "-It also seems that Elevation could be bias for the same reason soil could be.  \n",
    "--If trees grow in a certain elevation is that not concern for bias?  \n",
    "\n",
    "My point is that looking at the data almost every peice of data in some way point directly to a location.  \n",
    "But the idea of a bias is that if you get new information from somewhere else that contained a different soil type   \n",
    "in a differnt elevation and in a different wilderness area you would end up the wrong tree type because the model cant generalize well on biased data. \n",
    "\n",
    "Its hard to say that we would end up with a different soil type and different elevation when looking at what trees need to grow properly.   \n",
    "For example - Trees need specific tempurture ranges, specific watering amounts, specific soil acidity or alkalinity, and nutrients that the trees roots are able to access in that soil type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the number assosiated with df.class to a range from 0 - 6\n",
    "new_class = []\n",
    "for i in df['class']:\n",
    "    new_labels = i - 1\n",
    "    new_class.append(new_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "1    283301\n",
      "0    211840\n",
      "2     35754\n",
      "6     20510\n",
      "5     17367\n",
      "4      9493\n",
      "3      2747\n",
      "Name: count, dtype: int64\n",
      "Wilderness_Area1\n",
      "0    320216\n",
      "1    260796\n",
      "Name: count, dtype: int64\n",
      "Wilderness_Area2\n",
      "0    551128\n",
      "1     29884\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# add the new range of number to the class column\n",
    "df['class'] = new_class\n",
    "# check and make sure the range of numbers is changed\n",
    "print(df['class'].value_counts())\n",
    "# what is the distribution of yes and no in wilderness areas\n",
    "print(df['Wilderness_Area1'].value_counts())\n",
    "print(df['Wilderness_Area2'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperate Features And Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points']\n"
     ]
    }
   ],
   "source": [
    "# condenses the amount of data to make running models quicker\n",
    "# could cause inbalanced data in the training data - only use if your computer is super slow\n",
    "# random_seed = 42\n",
    "# feature_sample = df.sample(n=100000, random_state = random_seed) ## uncomment if you need this code\n",
    "\n",
    "# drop the wilderness and soil type columns because they dont need to be normalized. - we will bring these columns back\n",
    "drop_columns = df.columns[10:54]\n",
    "\n",
    "# create features\n",
    "features = df.drop(['class'], axis=1)\n",
    "features = features.drop(drop_columns, axis=1)\n",
    "feature_names = [i for i in features]\n",
    "\n",
    "# confirm we have the righe features\n",
    "print(feature_names)\n",
    "\n",
    "# create labels \n",
    "labels = df['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "feature_train, feature_test, label_train, label_test = train_test_split(features, labels, test_size=0.2, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the Data \n",
    "\n",
    "### We need to normalize the data so that every value is between 0 - 1. \n",
    "### This is how the Keras Model interprets information the easiest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.59815361 0.03376521 0.00377265 ... 0.04678086 0.02772898 0.60249216]\n",
      " [0.65775272 0.04353564 0.00557599 ... 0.05404424 0.03774518 0.16985333]\n",
      " [0.63158638 0.06256104 0.000747   ... 0.04369935 0.0302534  0.42186684]\n",
      " ...\n",
      " [0.56541143 0.01403631 0.00125967 ... 0.04102922 0.02375376 0.62389606]\n",
      " [0.56287816 0.05327365 0.00157718 ... 0.04135717 0.03136837 0.07360175]\n",
      " [0.54570083 0.00912882 0.00101431 ... 0.03820582 0.02316017 0.51560952]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Normalize the features from both the train and test sets \n",
    "ct = ColumnTransformer([('normalize', Normalizer(), feature_names)], remainder='passthrough')\n",
    "feature_train = ct.fit_transform(feature_train)\n",
    "feature_test = ct.transform(feature_test)\n",
    "print(feature_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation\n",
    "\n",
    "## We are using a TensorFlow Keras Sequential Model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 512)               5632      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 178,567\n",
      "Trainable params: 178,567\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# make a path to a file to hold the best model as it goes through the iterations(epochs)\n",
    "checkpoint_path = 'dlsp-portfolio-starter-code/model-9-'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_path,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "# model = tf.keras.models.load_model('dlsp-portfolio-starter-code/model-9-') # uncomment this if you want to load an existing model and weights\n",
    "\n",
    "# build the model using relu(most common) activation with a high neuron count due to the size and complexity of the dataset. \n",
    "model = Sequential()\n",
    "model.add(layers.Dense(512, activation='relu', input_shape= feature_train.shape[1:]))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# compile the the optimizer, loss and metrics for the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adamax(learning_rate=.0068507), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# check the amount of parameters we are working with \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the Model\n",
    "\n",
    "This is a lot of data to look at. It's over 500,000 rows of data with 53 rows 500,000 X 53 is a lot of variables to look at.  \n",
    "That being said its going to take time to run this code depending on your machine/GPU.  \n",
    "I am running a quatro p1000 and each epoch at a batch size of 57 takes about 30 seconds or more.  \n",
    "\n",
    "The smaller the batch size the better a model can generalize to some extent. Also the smaller the batch size the longer the model will take per epoch.  \n",
    "Lower batch sizes around 30 takes about a minute or more per epoch. The opposite is also true. A batch size of 100 will take about 15 sec. but will under perform and overfit the model.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8155/8155 [==============================] - 31s 4ms/step - loss: 0.1363 - accuracy: 0.9472 - val_loss: 0.1878 - val_accuracy: 0.9344\n",
      "Epoch 2/10\n",
      "8155/8155 [==============================] - 31s 4ms/step - loss: 0.1358 - accuracy: 0.9469 - val_loss: 0.1898 - val_accuracy: 0.9348\n",
      "Epoch 3/10\n",
      "8151/8155 [============================>.] - ETA: 0s - loss: 0.1338 - accuracy: 0.9478INFO:tensorflow:Assets written to: dlsp-portfolio-starter-code\\model-9-\\assets\n",
      "8155/8155 [==============================] - 32s 4ms/step - loss: 0.1338 - accuracy: 0.9478 - val_loss: 0.1829 - val_accuracy: 0.9349\n",
      "Epoch 4/10\n",
      "8155/8155 [==============================] - 31s 4ms/step - loss: 0.1363 - accuracy: 0.9472 - val_loss: 0.1879 - val_accuracy: 0.9335\n",
      "Epoch 5/10\n",
      "8155/8155 [==============================] - 32s 4ms/step - loss: 0.1347 - accuracy: 0.9481 - val_loss: 0.1908 - val_accuracy: 0.9328\n",
      "Epoch 6/10\n",
      "8155/8155 [==============================] - 30s 4ms/step - loss: 0.1361 - accuracy: 0.9468 - val_loss: 0.1891 - val_accuracy: 0.9343\n",
      "Epoch 7/10\n",
      "8155/8155 [==============================] - 31s 4ms/step - loss: 0.1345 - accuracy: 0.9478 - val_loss: 0.1996 - val_accuracy: 0.9318\n",
      "Epoch 8/10\n",
      "8143/8155 [============================>.] - ETA: 0s - loss: 0.1364 - accuracy: 0.9472INFO:tensorflow:Assets written to: dlsp-portfolio-starter-code\\model-9-\\assets\n",
      "8155/8155 [==============================] - 32s 4ms/step - loss: 0.1364 - accuracy: 0.9472 - val_loss: 0.1808 - val_accuracy: 0.9362\n",
      "Epoch 9/10\n",
      "8148/8155 [============================>.] - ETA: 0s - loss: 0.1339 - accuracy: 0.9482INFO:tensorflow:Assets written to: dlsp-portfolio-starter-code\\model-9-\\assets\n",
      "8155/8155 [==============================] - 31s 4ms/step - loss: 0.1339 - accuracy: 0.9482 - val_loss: 0.1805 - val_accuracy: 0.9358\n",
      "Epoch 10/10\n",
      "8155/8155 [==============================] - 32s 4ms/step - loss: 0.1340 - accuracy: 0.9476 - val_loss: 0.1936 - val_accuracy: 0.9332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21e5182b9a0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(feature_train, label_train, epochs=10, batch_size=57,  validation_data=(feature_test, label_test), callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this model for 300 epochs I got a validation accuracy of 94%. This is a great number to get considering some imbalance in the dataset.   \n",
    "We could get better scores and predictions if we had a more balanced dataset. The next cell below shows that imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Prediction \n",
    "\n",
    "## Shows the accruacy score of each categoical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3632/3632 [==============================] - 5s 1ms/step\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "           spruce       0.92      0.95      0.94     42368\n",
      "   lodgepole_pine       0.95      0.93      0.94     56661\n",
      "   ponderosa_pine       0.94      0.92      0.93      7151\n",
      "cottonwood_willow       0.83      0.84      0.83       549\n",
      "            aspen       0.84      0.83      0.83      1899\n",
      "      douglas_fir       0.89      0.86      0.88      3473\n",
      "        krummholz       0.94      0.95      0.94      4102\n",
      "\n",
      "         accuracy                           0.94    116203\n",
      "        macro avg       0.90      0.90      0.90    116203\n",
      "     weighted avg       0.94      0.94      0.94    116203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load and test the saved model\n",
    "model = tf.keras.models.load_model('dlsp-portfolio-starter-code/model-9-') # uncomment if you want to load and predict the saved checkpoint model.\n",
    "names = ['spruce','lodgepole_pine', 'ponderosa_pine', 'cottonwood_willow', 'aspen', 'douglas_fir', 'krummholz']\n",
    "y_estimate = model.predict(feature_test)\n",
    "y_estimate = np.argmax(y_estimate, axis=1)\n",
    "y_true = label_test\n",
    "print(classification_report(y_true, y_estimate, target_names= names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the support column we can see that cottonwood_willow has a very very small amount of data to train on compared to spruce or lodgepole_pine.  \n",
    "If we could collect more data on the smaller datasets we could get more accurate predictions in future models.  \n",
    "That being said their could be geographical issues collecting that data. Those trees might just be in decline and we just dont have trees to collect data on.  \n",
    "It's possible changes in climate or deforestation might be a cause of that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDownloads/dlsp-portfolio-starter-code/model-931\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# run code if you want to save the final model.\n",
    "model.save('Downloads/dlsp-portfolio-starter-code/model-931')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Search Cross Validation \n",
    "## Looks for the best parameters within the listed parameter Min/Max "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Taylor\\AppData\\Local\\Temp\\ipykernel_3508\\2650271943.py:26: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_model = KerasClassifier(build_fn=create_model, epochs=10, verbose=1, validation_data=(x_test, y_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5253/5253 [==============================] - 25s 5ms/step - loss: 1.5387 - accuracy: 0.5806 - val_loss: 1.0346 - val_accuracy: 0.5404\n",
      "Epoch 2/10\n",
      "5253/5253 [==============================] - 25s 5ms/step - loss: 0.7346 - accuracy: 0.6837 - val_loss: 0.7634 - val_accuracy: 0.6721\n",
      "Epoch 3/10\n",
      "5253/5253 [==============================] - 24s 5ms/step - loss: 0.6532 - accuracy: 0.7160 - val_loss: 0.7344 - val_accuracy: 0.6588\n",
      "Epoch 4/10\n",
      "5253/5253 [==============================] - 25s 5ms/step - loss: 0.6060 - accuracy: 0.7370 - val_loss: 0.6498 - val_accuracy: 0.7137\n",
      "Epoch 5/10\n",
      "5253/5253 [==============================] - 25s 5ms/step - loss: 0.5686 - accuracy: 0.7535 - val_loss: 0.5653 - val_accuracy: 0.7592\n",
      "Epoch 6/10\n",
      "5253/5253 [==============================] - 25s 5ms/step - loss: 0.5351 - accuracy: 0.7677 - val_loss: 0.5296 - val_accuracy: 0.7687\n",
      "Epoch 7/10\n",
      "5253/5253 [==============================] - 26s 5ms/step - loss: 0.5091 - accuracy: 0.7794 - val_loss: 0.4921 - val_accuracy: 0.7842\n",
      "Epoch 8/10\n",
      "5253/5253 [==============================] - 25s 5ms/step - loss: 0.4926 - accuracy: 0.7862 - val_loss: 0.5001 - val_accuracy: 0.7820\n",
      "Epoch 9/10\n",
      "5253/5253 [==============================] - 24s 5ms/step - loss: 0.4715 - accuracy: 0.7965 - val_loss: 0.4876 - val_accuracy: 0.7901\n",
      "Epoch 10/10\n",
      "5253/5253 [==============================] - 24s 5ms/step - loss: 0.4577 - accuracy: 0.8024 - val_loss: 0.4493 - val_accuracy: 0.8065\n",
      "4842/4842 [==============================] - 6s 1ms/step\n",
      "Epoch 1/10\n",
      "5253/5253 [==============================] - 25s 5ms/step - loss: 1.4660 - accuracy: 0.5847 - val_loss: 0.9079 - val_accuracy: 0.6326\n",
      "Epoch 2/10\n",
      "5253/5253 [==============================] - 25s 5ms/step - loss: 0.7320 - accuracy: 0.6839 - val_loss: 0.6734 - val_accuracy: 0.7054\n",
      "Epoch 3/10\n",
      "5253/5253 [==============================] - 25s 5ms/step - loss: 0.6652 - accuracy: 0.7107 - val_loss: 0.6656 - val_accuracy: 0.7076\n",
      "Epoch 4/10\n",
      "5253/5253 [==============================] - 25s 5ms/step - loss: 0.6174 - accuracy: 0.7305 - val_loss: 0.5953 - val_accuracy: 0.7406\n",
      "Epoch 5/10\n",
      "5253/5253 [==============================] - 25s 5ms/step - loss: 0.5793 - accuracy: 0.7471 - val_loss: 0.5903 - val_accuracy: 0.7417\n",
      "Epoch 6/10\n",
      "5253/5253 [==============================] - 25s 5ms/step - loss: 0.5484 - accuracy: 0.7595 - val_loss: 0.5339 - val_accuracy: 0.7679\n",
      "Epoch 7/10\n",
      "5253/5253 [==============================] - 25s 5ms/step - loss: 0.5216 - accuracy: 0.7724 - val_loss: 0.5040 - val_accuracy: 0.7800\n",
      "Epoch 8/10\n",
      "5253/5253 [==============================] - 25s 5ms/step - loss: 0.5007 - accuracy: 0.7823 - val_loss: 0.4892 - val_accuracy: 0.7873\n",
      "Epoch 9/10\n",
      "5253/5253 [==============================] - 25s 5ms/step - loss: 0.4823 - accuracy: 0.7910 - val_loss: 0.4842 - val_accuracy: 0.7906\n",
      "Epoch 10/10\n",
      "5253/5253 [==============================] - 26s 5ms/step - loss: 0.4656 - accuracy: 0.7981 - val_loss: 0.4740 - val_accuracy: 0.7942\n",
      "4842/4842 [==============================] - 6s 1ms/step\n",
      "Epoch 1/10\n",
      "5253/5253 [==============================] - 25s 5ms/step - loss: 1.6270 - accuracy: 0.5820 - val_loss: 0.7940 - val_accuracy: 0.6639\n",
      "Epoch 2/10\n",
      "5253/5253 [==============================] - 24s 5ms/step - loss: 0.7338 - accuracy: 0.6821 - val_loss: 0.7317 - val_accuracy: 0.6990\n",
      "Epoch 3/10\n",
      "5253/5253 [==============================] - 25s 5ms/step - loss: 0.6703 - accuracy: 0.7080 - val_loss: 0.6347 - val_accuracy: 0.7267\n",
      "Epoch 4/10\n",
      "5253/5253 [==============================] - 25s 5ms/step - loss: 0.6180 - accuracy: 0.7289 - val_loss: 0.5973 - val_accuracy: 0.7352\n",
      "Epoch 5/10\n",
      "5253/5253 [==============================] - 26s 5ms/step - loss: 0.5760 - accuracy: 0.7462 - val_loss: 0.5677 - val_accuracy: 0.7516\n",
      "Epoch 6/10\n",
      "5253/5253 [==============================] - 26s 5ms/step - loss: 0.5467 - accuracy: 0.7598 - val_loss: 0.5152 - val_accuracy: 0.7733\n",
      "Epoch 7/10\n",
      "5253/5253 [==============================] - 25s 5ms/step - loss: 0.5226 - accuracy: 0.7702 - val_loss: 0.5090 - val_accuracy: 0.7779\n",
      "Epoch 8/10\n",
      "5253/5253 [==============================] - 24s 5ms/step - loss: 0.5017 - accuracy: 0.7811 - val_loss: 0.5145 - val_accuracy: 0.7749\n",
      "Epoch 9/10\n",
      "5253/5253 [==============================] - 25s 5ms/step - loss: 0.4850 - accuracy: 0.7877 - val_loss: 0.4722 - val_accuracy: 0.7936\n",
      "Epoch 10/10\n",
      "5253/5253 [==============================] - 25s 5ms/step - loss: 0.4701 - accuracy: 0.7948 - val_loss: 0.4616 - val_accuracy: 0.7990\n",
      "4842/4842 [==============================] - 6s 1ms/step\n",
      "Epoch 1/10\n",
      "7043/7043 [==============================] - 33s 5ms/step - loss: 1.3153 - accuracy: 0.6064 - val_loss: 0.7454 - val_accuracy: 0.6864\n",
      "Epoch 2/10\n",
      "7043/7043 [==============================] - 34s 5ms/step - loss: 0.7028 - accuracy: 0.6954 - val_loss: 0.6535 - val_accuracy: 0.7197\n",
      "Epoch 3/10\n",
      "7043/7043 [==============================] - 34s 5ms/step - loss: 0.6374 - accuracy: 0.7222 - val_loss: 0.6686 - val_accuracy: 0.7197\n",
      "Epoch 4/10\n",
      "7043/7043 [==============================] - 32s 5ms/step - loss: 0.5896 - accuracy: 0.7426 - val_loss: 0.5682 - val_accuracy: 0.7511\n",
      "Epoch 5/10\n",
      "7043/7043 [==============================] - 33s 5ms/step - loss: 0.5549 - accuracy: 0.7581 - val_loss: 0.5369 - val_accuracy: 0.7691\n",
      "Epoch 6/10\n",
      "7043/7043 [==============================] - 33s 5ms/step - loss: 0.5298 - accuracy: 0.7694 - val_loss: 0.5093 - val_accuracy: 0.7803\n",
      "Epoch 7/10\n",
      "7043/7043 [==============================] - 33s 5ms/step - loss: 0.5080 - accuracy: 0.7795 - val_loss: 0.5023 - val_accuracy: 0.7830\n",
      "Epoch 8/10\n",
      "7043/7043 [==============================] - 33s 5ms/step - loss: 0.4869 - accuracy: 0.7889 - val_loss: 0.4714 - val_accuracy: 0.7990\n",
      "Epoch 9/10\n",
      "7043/7043 [==============================] - 33s 5ms/step - loss: 0.4701 - accuracy: 0.7975 - val_loss: 0.4637 - val_accuracy: 0.7996\n",
      "Epoch 10/10\n",
      "7043/7043 [==============================] - 33s 5ms/step - loss: 0.4560 - accuracy: 0.8033 - val_loss: 0.4682 - val_accuracy: 0.7986\n",
      "4842/4842 [==============================] - 6s 1ms/step\n",
      "Epoch 1/10\n",
      "7043/7043 [==============================] - 33s 5ms/step - loss: 1.2800 - accuracy: 0.6016 - val_loss: 0.7787 - val_accuracy: 0.6755\n",
      "Epoch 2/10\n",
      "7043/7043 [==============================] - 33s 5ms/step - loss: 0.7129 - accuracy: 0.6917 - val_loss: 0.6592 - val_accuracy: 0.7213\n",
      "Epoch 3/10\n",
      "7043/7043 [==============================] - 33s 5ms/step - loss: 0.6444 - accuracy: 0.7214 - val_loss: 0.6343 - val_accuracy: 0.7278\n",
      "Epoch 4/10\n",
      "7043/7043 [==============================] - 33s 5ms/step - loss: 0.5988 - accuracy: 0.7397 - val_loss: 0.5752 - val_accuracy: 0.7524\n",
      "Epoch 5/10\n",
      "7043/7043 [==============================] - 33s 5ms/step - loss: 0.5622 - accuracy: 0.7551 - val_loss: 0.5499 - val_accuracy: 0.7659\n",
      "Epoch 6/10\n",
      "7043/7043 [==============================] - 33s 5ms/step - loss: 0.5341 - accuracy: 0.7678 - val_loss: 0.5385 - val_accuracy: 0.7641\n",
      "Epoch 7/10\n",
      "7043/7043 [==============================] - 33s 5ms/step - loss: 0.5100 - accuracy: 0.7787 - val_loss: 0.4923 - val_accuracy: 0.7839\n",
      "Epoch 8/10\n",
      "7043/7043 [==============================] - 33s 5ms/step - loss: 0.4905 - accuracy: 0.7878 - val_loss: 0.4660 - val_accuracy: 0.7995\n",
      "Epoch 9/10\n",
      "7043/7043 [==============================] - 32s 5ms/step - loss: 0.4730 - accuracy: 0.7955 - val_loss: 0.4660 - val_accuracy: 0.8002\n",
      "Epoch 10/10\n",
      "7043/7043 [==============================] - 32s 5ms/step - loss: 0.4587 - accuracy: 0.8020 - val_loss: 0.4512 - val_accuracy: 0.8047\n",
      "4842/4842 [==============================] - 6s 1ms/step\n",
      "Epoch 1/10\n",
      "7043/7043 [==============================] - 33s 5ms/step - loss: 1.2721 - accuracy: 0.6023 - val_loss: 0.7130 - val_accuracy: 0.6942\n",
      "Epoch 2/10\n",
      "7043/7043 [==============================] - 32s 5ms/step - loss: 0.7073 - accuracy: 0.6913 - val_loss: 0.7485 - val_accuracy: 0.6648\n",
      "Epoch 3/10\n",
      "7043/7043 [==============================] - 32s 5ms/step - loss: 0.6453 - accuracy: 0.7181 - val_loss: 0.6147 - val_accuracy: 0.7334\n",
      "Epoch 4/10\n",
      "7043/7043 [==============================] - 32s 5ms/step - loss: 0.5993 - accuracy: 0.7384 - val_loss: 0.5883 - val_accuracy: 0.7471\n",
      "Epoch 5/10\n",
      "7043/7043 [==============================] - 32s 5ms/step - loss: 0.5610 - accuracy: 0.7546 - val_loss: 0.5512 - val_accuracy: 0.7618\n",
      "Epoch 6/10\n",
      "7043/7043 [==============================] - 32s 5ms/step - loss: 0.5317 - accuracy: 0.7682 - val_loss: 0.6019 - val_accuracy: 0.7438\n",
      "Epoch 7/10\n",
      "7043/7043 [==============================] - 32s 5ms/step - loss: 0.5060 - accuracy: 0.7799 - val_loss: 0.4736 - val_accuracy: 0.7970\n",
      "Epoch 8/10\n",
      "7043/7043 [==============================] - 32s 5ms/step - loss: 0.4849 - accuracy: 0.7899 - val_loss: 0.4844 - val_accuracy: 0.7904\n",
      "Epoch 9/10\n",
      "7043/7043 [==============================] - 32s 5ms/step - loss: 0.4673 - accuracy: 0.7980 - val_loss: 0.4798 - val_accuracy: 0.7939\n",
      "Epoch 10/10\n",
      "7043/7043 [==============================] - 32s 5ms/step - loss: 0.4508 - accuracy: 0.8059 - val_loss: 0.4439 - val_accuracy: 0.8047\n",
      "4842/4842 [==============================] - 6s 1ms/step\n",
      "Epoch 1/10\n",
      "5437/5437 [==============================] - 26s 5ms/step - loss: 1.3872 - accuracy: 0.5942 - val_loss: 0.7630 - val_accuracy: 0.6752\n",
      "Epoch 2/10\n",
      "5437/5437 [==============================] - 25s 5ms/step - loss: 0.7204 - accuracy: 0.6883 - val_loss: 0.7347 - val_accuracy: 0.6826\n",
      "Epoch 3/10\n",
      "5437/5437 [==============================] - 25s 5ms/step - loss: 0.6554 - accuracy: 0.7144 - val_loss: 0.6129 - val_accuracy: 0.7346\n",
      "Epoch 4/10\n",
      "5437/5437 [==============================] - 25s 5ms/step - loss: 0.6067 - accuracy: 0.7347 - val_loss: 0.5775 - val_accuracy: 0.7522\n",
      "Epoch 5/10\n",
      "5437/5437 [==============================] - 25s 5ms/step - loss: 0.5691 - accuracy: 0.7515 - val_loss: 0.5629 - val_accuracy: 0.7523\n",
      "Epoch 6/10\n",
      "5437/5437 [==============================] - 25s 5ms/step - loss: 0.5387 - accuracy: 0.7647 - val_loss: 0.5224 - val_accuracy: 0.7712\n",
      "Epoch 7/10\n",
      "5437/5437 [==============================] - 25s 5ms/step - loss: 0.5152 - accuracy: 0.7758 - val_loss: 0.5090 - val_accuracy: 0.7811\n",
      "Epoch 8/10\n",
      "5437/5437 [==============================] - 27s 5ms/step - loss: 0.4948 - accuracy: 0.7851 - val_loss: 0.4705 - val_accuracy: 0.7989\n",
      "Epoch 9/10\n",
      "5437/5437 [==============================] - 27s 5ms/step - loss: 0.4768 - accuracy: 0.7935 - val_loss: 0.4875 - val_accuracy: 0.7880\n",
      "Epoch 10/10\n",
      "5437/5437 [==============================] - 27s 5ms/step - loss: 0.4619 - accuracy: 0.8003 - val_loss: 0.4748 - val_accuracy: 0.7971\n",
      "4842/4842 [==============================] - 7s 1ms/step\n",
      "Epoch 1/10\n",
      "5437/5437 [==============================] - 28s 5ms/step - loss: 1.6061 - accuracy: 0.5790 - val_loss: 0.7764 - val_accuracy: 0.6696\n",
      "Epoch 2/10\n",
      "5437/5437 [==============================] - 27s 5ms/step - loss: 0.7241 - accuracy: 0.6881 - val_loss: 0.6543 - val_accuracy: 0.7162\n",
      "Epoch 3/10\n",
      "5437/5437 [==============================] - 27s 5ms/step - loss: 0.6480 - accuracy: 0.7171 - val_loss: 0.5978 - val_accuracy: 0.7367\n",
      "Epoch 4/10\n",
      "5437/5437 [==============================] - 27s 5ms/step - loss: 0.5941 - accuracy: 0.7398 - val_loss: 0.5720 - val_accuracy: 0.7513\n",
      "Epoch 5/10\n",
      "5437/5437 [==============================] - 27s 5ms/step - loss: 0.5573 - accuracy: 0.7566 - val_loss: 0.5132 - val_accuracy: 0.7779\n",
      "Epoch 6/10\n",
      "5437/5437 [==============================] - 27s 5ms/step - loss: 0.5262 - accuracy: 0.7702 - val_loss: 0.4915 - val_accuracy: 0.7890\n",
      "Epoch 7/10\n",
      "5437/5437 [==============================] - 27s 5ms/step - loss: 0.5022 - accuracy: 0.7822 - val_loss: 0.4730 - val_accuracy: 0.7960\n",
      "Epoch 8/10\n",
      "5437/5437 [==============================] - 27s 5ms/step - loss: 0.4840 - accuracy: 0.7904 - val_loss: 0.4714 - val_accuracy: 0.7992\n",
      "Epoch 9/10\n",
      "5437/5437 [==============================] - 27s 5ms/step - loss: 0.4653 - accuracy: 0.7994 - val_loss: 0.4567 - val_accuracy: 0.8033\n",
      "Epoch 10/10\n",
      "5437/5437 [==============================] - 27s 5ms/step - loss: 0.4521 - accuracy: 0.8047 - val_loss: 0.4354 - val_accuracy: 0.8140\n",
      "4842/4842 [==============================] - 7s 1ms/step\n",
      "Epoch 1/10\n",
      "5437/5437 [==============================] - 28s 5ms/step - loss: 1.5916 - accuracy: 0.5781 - val_loss: 0.8320 - val_accuracy: 0.6555\n",
      "Epoch 2/10\n",
      "5437/5437 [==============================] - 27s 5ms/step - loss: 0.7199 - accuracy: 0.6884 - val_loss: 0.6722 - val_accuracy: 0.7049\n",
      "Epoch 3/10\n",
      "5437/5437 [==============================] - 27s 5ms/step - loss: 0.6496 - accuracy: 0.7163 - val_loss: 0.6042 - val_accuracy: 0.7390\n",
      "Epoch 4/10\n",
      "5437/5437 [==============================] - 27s 5ms/step - loss: 0.6015 - accuracy: 0.7368 - val_loss: 0.5968 - val_accuracy: 0.7399\n",
      "Epoch 5/10\n",
      "5437/5437 [==============================] - 27s 5ms/step - loss: 0.5577 - accuracy: 0.7562 - val_loss: 0.5619 - val_accuracy: 0.7582\n",
      "Epoch 6/10\n",
      "5437/5437 [==============================] - 27s 5ms/step - loss: 0.5259 - accuracy: 0.7710 - val_loss: 0.5063 - val_accuracy: 0.7801\n",
      "Epoch 7/10\n",
      "5437/5437 [==============================] - 27s 5ms/step - loss: 0.5016 - accuracy: 0.7807 - val_loss: 0.4901 - val_accuracy: 0.7882\n",
      "Epoch 8/10\n",
      "5437/5437 [==============================] - 27s 5ms/step - loss: 0.4797 - accuracy: 0.7914 - val_loss: 0.4636 - val_accuracy: 0.7977\n",
      "Epoch 9/10\n",
      "5437/5437 [==============================] - 26s 5ms/step - loss: 0.4606 - accuracy: 0.7998 - val_loss: 0.4626 - val_accuracy: 0.7974\n",
      "Epoch 10/10\n",
      "5437/5437 [==============================] - 26s 5ms/step - loss: 0.4442 - accuracy: 0.8072 - val_loss: 0.4298 - val_accuracy: 0.8166\n",
      "4842/4842 [==============================] - 6s 1ms/step\n",
      "Epoch 1/10\n",
      "5165/5165 [==============================] - 25s 5ms/step - loss: 1.5159 - accuracy: 0.5822 - val_loss: 0.7657 - val_accuracy: 0.6517\n",
      "Epoch 2/10\n",
      "5165/5165 [==============================] - 24s 5ms/step - loss: 0.7321 - accuracy: 0.6841 - val_loss: 0.6755 - val_accuracy: 0.7087\n",
      "Epoch 3/10\n",
      "5165/5165 [==============================] - 25s 5ms/step - loss: 0.6644 - accuracy: 0.7116 - val_loss: 0.6460 - val_accuracy: 0.7131\n",
      "Epoch 4/10\n",
      "5165/5165 [==============================] - 25s 5ms/step - loss: 0.6137 - accuracy: 0.7333 - val_loss: 0.6006 - val_accuracy: 0.7383\n",
      "Epoch 5/10\n",
      "5165/5165 [==============================] - 25s 5ms/step - loss: 0.5692 - accuracy: 0.7513 - val_loss: 0.5740 - val_accuracy: 0.7500\n",
      "Epoch 6/10\n",
      "5165/5165 [==============================] - 25s 5ms/step - loss: 0.5383 - accuracy: 0.7647 - val_loss: 0.5234 - val_accuracy: 0.7704\n",
      "Epoch 7/10\n",
      "5165/5165 [==============================] - 25s 5ms/step - loss: 0.5102 - accuracy: 0.7778 - val_loss: 0.5317 - val_accuracy: 0.7667\n",
      "Epoch 8/10\n",
      "5165/5165 [==============================] - 25s 5ms/step - loss: 0.4872 - accuracy: 0.7879 - val_loss: 0.4957 - val_accuracy: 0.7823\n",
      "Epoch 9/10\n",
      "5165/5165 [==============================] - 25s 5ms/step - loss: 0.4706 - accuracy: 0.7963 - val_loss: 0.4679 - val_accuracy: 0.8014\n",
      "Epoch 10/10\n",
      "5165/5165 [==============================] - 87s 17ms/step - loss: 0.4549 - accuracy: 0.8032 - val_loss: 0.4540 - val_accuracy: 0.8052\n",
      "4842/4842 [==============================] - 31s 6ms/step\n",
      "Epoch 1/10\n",
      "5165/5165 [==============================] - 109s 21ms/step - loss: 1.6383 - accuracy: 0.5768 - val_loss: 0.7872 - val_accuracy: 0.6769\n",
      "Epoch 2/10\n",
      "5165/5165 [==============================] - 106s 21ms/step - loss: 0.7373 - accuracy: 0.6820 - val_loss: 0.7015 - val_accuracy: 0.6919\n",
      "Epoch 3/10\n",
      "5165/5165 [==============================] - 113s 22ms/step - loss: 0.6634 - accuracy: 0.7119 - val_loss: 0.6366 - val_accuracy: 0.7151\n",
      "Epoch 4/10\n",
      "5165/5165 [==============================] - 99s 19ms/step - loss: 0.6143 - accuracy: 0.7320 - val_loss: 0.6051 - val_accuracy: 0.7288\n",
      "Epoch 5/10\n",
      "5165/5165 [==============================] - 54s 10ms/step - loss: 0.5732 - accuracy: 0.7500 - val_loss: 0.5575 - val_accuracy: 0.7607\n",
      "Epoch 6/10\n",
      "5165/5165 [==============================] - 40s 8ms/step - loss: 0.5469 - accuracy: 0.7620 - val_loss: 0.5330 - val_accuracy: 0.7684\n",
      "Epoch 7/10\n",
      "5165/5165 [==============================] - 37s 7ms/step - loss: 0.5233 - accuracy: 0.7724 - val_loss: 0.5026 - val_accuracy: 0.7818\n",
      "Epoch 8/10\n",
      "5165/5165 [==============================] - 37s 7ms/step - loss: 0.5017 - accuracy: 0.7824 - val_loss: 0.4826 - val_accuracy: 0.7926\n",
      "Epoch 9/10\n",
      "5165/5165 [==============================] - 37s 7ms/step - loss: 0.4830 - accuracy: 0.7902 - val_loss: 0.4638 - val_accuracy: 0.7986\n",
      "Epoch 10/10\n",
      "5165/5165 [==============================] - 37s 7ms/step - loss: 0.4672 - accuracy: 0.7977 - val_loss: 0.4667 - val_accuracy: 0.7988\n",
      "4842/4842 [==============================] - 8s 2ms/step\n",
      "Epoch 1/10\n",
      "5165/5165 [==============================] - 37s 7ms/step - loss: 1.2394 - accuracy: 0.5883 - val_loss: 0.8394 - val_accuracy: 0.6259\n",
      "Epoch 2/10\n",
      "5165/5165 [==============================] - 36s 7ms/step - loss: 0.7389 - accuracy: 0.6823 - val_loss: 0.6762 - val_accuracy: 0.7083\n",
      "Epoch 3/10\n",
      "5165/5165 [==============================] - 37s 7ms/step - loss: 0.6678 - accuracy: 0.7102 - val_loss: 0.6608 - val_accuracy: 0.7113\n",
      "Epoch 4/10\n",
      "5165/5165 [==============================] - 37s 7ms/step - loss: 0.6184 - accuracy: 0.7309 - val_loss: 0.5892 - val_accuracy: 0.7469\n",
      "Epoch 5/10\n",
      "5165/5165 [==============================] - 37s 7ms/step - loss: 0.5775 - accuracy: 0.7489 - val_loss: 0.5683 - val_accuracy: 0.7517\n",
      "Epoch 6/10\n",
      "5165/5165 [==============================] - 36s 7ms/step - loss: 0.5436 - accuracy: 0.7644 - val_loss: 0.5493 - val_accuracy: 0.7624\n",
      "Epoch 7/10\n",
      "5165/5165 [==============================] - 36s 7ms/step - loss: 0.5146 - accuracy: 0.7766 - val_loss: 0.4926 - val_accuracy: 0.7863\n",
      "Epoch 8/10\n",
      "5165/5165 [==============================] - 35s 7ms/step - loss: 0.4927 - accuracy: 0.7871 - val_loss: 0.4714 - val_accuracy: 0.7971\n",
      "Epoch 9/10\n",
      "5165/5165 [==============================] - 36s 7ms/step - loss: 0.4726 - accuracy: 0.7953 - val_loss: 0.4540 - val_accuracy: 0.8030\n",
      "Epoch 10/10\n",
      "5165/5165 [==============================] - 36s 7ms/step - loss: 0.4563 - accuracy: 0.8026 - val_loss: 0.4431 - val_accuracy: 0.8079\n",
      "4842/4842 [==============================] - 8s 2ms/step\n",
      "Epoch 1/10\n",
      "7378/7378 [==============================] - 53s 7ms/step - loss: 1.3343 - accuracy: 0.6028 - val_loss: 0.7230 - val_accuracy: 0.6947\n",
      "Epoch 2/10\n",
      "7378/7378 [==============================] - 52s 7ms/step - loss: 0.7149 - accuracy: 0.6906 - val_loss: 0.6751 - val_accuracy: 0.7079\n",
      "Epoch 3/10\n",
      "7378/7378 [==============================] - 53s 7ms/step - loss: 0.6470 - accuracy: 0.7184 - val_loss: 0.6344 - val_accuracy: 0.7212\n",
      "Epoch 4/10\n",
      "7378/7378 [==============================] - 53s 7ms/step - loss: 0.5976 - accuracy: 0.7392 - val_loss: 0.5951 - val_accuracy: 0.7400\n",
      "Epoch 5/10\n",
      "7378/7378 [==============================] - 54s 7ms/step - loss: 0.5620 - accuracy: 0.7545 - val_loss: 0.5638 - val_accuracy: 0.7542\n",
      "Epoch 6/10\n",
      "7378/7378 [==============================] - 53s 7ms/step - loss: 0.5324 - accuracy: 0.7682 - val_loss: 0.5121 - val_accuracy: 0.7783\n",
      "Epoch 7/10\n",
      "7378/7378 [==============================] - 53s 7ms/step - loss: 0.5073 - accuracy: 0.7794 - val_loss: 0.4914 - val_accuracy: 0.7875\n",
      "Epoch 8/10\n",
      "7378/7378 [==============================] - 52s 7ms/step - loss: 0.4850 - accuracy: 0.7889 - val_loss: 0.4814 - val_accuracy: 0.7872\n",
      "Epoch 9/10\n",
      "7378/7378 [==============================] - 55s 7ms/step - loss: 0.4664 - accuracy: 0.7988 - val_loss: 0.4782 - val_accuracy: 0.7937\n",
      "Epoch 10/10\n",
      "7378/7378 [==============================] - 52s 7ms/step - loss: 0.4510 - accuracy: 0.8053 - val_loss: 0.4450 - val_accuracy: 0.8080\n",
      "4842/4842 [==============================] - 9s 2ms/step\n",
      "Epoch 1/10\n",
      "7378/7378 [==============================] - 52s 7ms/step - loss: 1.4304 - accuracy: 0.6016 - val_loss: 0.7375 - val_accuracy: 0.6885\n",
      "Epoch 2/10\n",
      "7378/7378 [==============================] - 52s 7ms/step - loss: 0.7090 - accuracy: 0.6919 - val_loss: 0.6655 - val_accuracy: 0.7088\n",
      "Epoch 3/10\n",
      "7378/7378 [==============================] - 52s 7ms/step - loss: 0.6409 - accuracy: 0.7205 - val_loss: 0.6250 - val_accuracy: 0.7213\n",
      "Epoch 4/10\n",
      "7378/7378 [==============================] - 52s 7ms/step - loss: 0.5904 - accuracy: 0.7426 - val_loss: 0.5713 - val_accuracy: 0.7497\n",
      "Epoch 5/10\n",
      "7378/7378 [==============================] - 51s 7ms/step - loss: 0.5550 - accuracy: 0.7586 - val_loss: 0.5628 - val_accuracy: 0.7604\n",
      "Epoch 6/10\n",
      "7378/7378 [==============================] - 51s 7ms/step - loss: 0.5231 - accuracy: 0.7728 - val_loss: 0.5028 - val_accuracy: 0.7856\n",
      "Epoch 7/10\n",
      "7378/7378 [==============================] - 52s 7ms/step - loss: 0.4974 - accuracy: 0.7851 - val_loss: 0.5098 - val_accuracy: 0.7812\n",
      "Epoch 8/10\n",
      "7378/7378 [==============================] - 52s 7ms/step - loss: 0.4793 - accuracy: 0.7930 - val_loss: 0.4630 - val_accuracy: 0.7989\n",
      "Epoch 9/10\n",
      "7378/7378 [==============================] - 58s 8ms/step - loss: 0.4626 - accuracy: 0.8002 - val_loss: 0.4488 - val_accuracy: 0.8077\n",
      "Epoch 10/10\n",
      "7378/7378 [==============================] - 52s 7ms/step - loss: 0.4465 - accuracy: 0.8082 - val_loss: 0.4379 - val_accuracy: 0.8137\n",
      "4842/4842 [==============================] - 9s 2ms/step\n",
      "Epoch 1/10\n",
      "7378/7378 [==============================] - 52s 7ms/step - loss: 1.2753 - accuracy: 0.6095 - val_loss: 0.8076 - val_accuracy: 0.6302\n",
      "Epoch 2/10\n",
      "7378/7378 [==============================] - 49s 7ms/step - loss: 0.7062 - accuracy: 0.6931 - val_loss: 0.7177 - val_accuracy: 0.6786\n",
      "Epoch 3/10\n",
      "7378/7378 [==============================] - 51s 7ms/step - loss: 0.6375 - accuracy: 0.7220 - val_loss: 0.6048 - val_accuracy: 0.7392\n",
      "Epoch 4/10\n",
      "7378/7378 [==============================] - 52s 7ms/step - loss: 0.5931 - accuracy: 0.7412 - val_loss: 0.5916 - val_accuracy: 0.7445\n",
      "Epoch 5/10\n",
      "7378/7378 [==============================] - 53s 7ms/step - loss: 0.5563 - accuracy: 0.7579 - val_loss: 0.5327 - val_accuracy: 0.7662\n",
      "Epoch 6/10\n",
      "7378/7378 [==============================] - 54s 7ms/step - loss: 0.5274 - accuracy: 0.7696 - val_loss: 0.5108 - val_accuracy: 0.7796\n",
      "Epoch 7/10\n",
      "7378/7378 [==============================] - 50s 7ms/step - loss: 0.5037 - accuracy: 0.7803 - val_loss: 0.5121 - val_accuracy: 0.7728\n",
      "Epoch 8/10\n",
      "7378/7378 [==============================] - 55s 7ms/step - loss: 0.4846 - accuracy: 0.7891 - val_loss: 0.4897 - val_accuracy: 0.7865\n",
      "Epoch 9/10\n",
      "7378/7378 [==============================] - 55s 7ms/step - loss: 0.4695 - accuracy: 0.7955 - val_loss: 0.4950 - val_accuracy: 0.7837\n",
      "Epoch 10/10\n",
      "7378/7378 [==============================] - 54s 7ms/step - loss: 0.4551 - accuracy: 0.8024 - val_loss: 0.4678 - val_accuracy: 0.7960\n",
      "4842/4842 [==============================] - 9s 2ms/step\n",
      "Epoch 1/10\n",
      "8155/8155 [==============================] - 56s 7ms/step - loss: 1.1590 - accuracy: 0.6266 - val_loss: 0.6974 - val_accuracy: 0.7042\n",
      "Epoch 2/10\n",
      "8155/8155 [==============================] - 55s 7ms/step - loss: 0.6702 - accuracy: 0.7102 - val_loss: 0.7916 - val_accuracy: 0.6384\n",
      "Epoch 3/10\n",
      "8155/8155 [==============================] - 54s 7ms/step - loss: 0.5987 - accuracy: 0.7397 - val_loss: 0.5545 - val_accuracy: 0.7606\n",
      "Epoch 4/10\n",
      "8155/8155 [==============================] - 54s 7ms/step - loss: 0.5465 - accuracy: 0.7623 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
      "Epoch 5/10\n",
      "8155/8155 [==============================] - 56s 7ms/step - loss: 0.5104 - accuracy: 0.7781 - val_loss: 0.4871 - val_accuracy: 0.7864\n",
      "Epoch 6/10\n",
      "8155/8155 [==============================] - 65s 8ms/step - loss: 0.4835 - accuracy: 0.7905 - val_loss: 0.4636 - val_accuracy: 0.8005\n",
      "Epoch 7/10\n",
      "8155/8155 [==============================] - 55s 7ms/step - loss: 0.4597 - accuracy: 0.8004 - val_loss: 0.4375 - val_accuracy: 0.8107\n",
      "Epoch 8/10\n",
      "8155/8155 [==============================] - 47s 6ms/step - loss: 0.4409 - accuracy: 0.8097 - val_loss: 0.4715 - val_accuracy: 0.7953\n",
      "Epoch 9/10\n",
      "8155/8155 [==============================] - 45s 6ms/step - loss: 0.4246 - accuracy: 0.8174 - val_loss: 0.4254 - val_accuracy: 0.8171\n",
      "Epoch 10/10\n",
      "8155/8155 [==============================] - 51s 6ms/step - loss: 0.4098 - accuracy: 0.8243 - val_loss: 0.4048 - val_accuracy: 0.8256\n",
      "Best Parameters:  {'activation': 'relu', 'batch_size': 57, 'learning_rate': 0.006850703871388203, 'optimizer': 'adamax'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Function to create a Keras model\n",
    "def create_model(learning_rate=0.001, batch_size=64, activation='relu', optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation=activation, input_shape=(x_train.shape[1:])))\n",
    "    model.add(layers.Dense(256, activation=activation))\n",
    "    model.add(layers.Dense(128, activation=activation))\n",
    "    model.add(layers.Dense(64, activation=activation))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap the Keras model in a scikit-learn classifier\n",
    "keras_model = KerasClassifier(build_fn=create_model, epochs=10, verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "# Specify hyperparameter space for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'learning_rate': uniform(0.001, 0.006),\n",
    "    'batch_size': randint(32, 64),\n",
    "    'activation': ['relu'],\n",
    "    'optimizer' : ['adamax']\n",
    "    \n",
    "}\n",
    "\n",
    "# Define scoring function (you can use any metric suitable for your problem)\n",
    "scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# Generate synthetic data (replace with your actual data)\n",
    "\n",
    "\n",
    "# Create RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=keras_model,\n",
    "    param_distributions=param_dist,\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    n_iter=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best Parameters: \", random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8106426783605515\n",
      "{'mean_fit_time': array([249.8179125 , 327.54888813, 265.5462025 , 448.97699745,\n",
      "       526.72977042]), 'std_fit_time': array([  0.96093573,   3.46053334,   6.85088201, 157.69357347,\n",
      "         2.43115394]), 'mean_score_time': array([ 8.04122535,  8.06960646,  8.45916986, 19.24322987, 10.71003962]), 'std_score_time': array([ 0.03160856,  0.05284952,  0.26226119, 12.62113346,  0.20072238]), 'param_activation': masked_array(data=['relu', 'relu', 'relu', 'relu', 'relu'],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_batch_size': masked_array(data=[59, 44, 57, 60, 42],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_learning_rate': masked_array(data=[0.0027053511266219815, 0.005944306073906301,\n",
      "                   0.006850703871388203, 0.005978753744738821,\n",
      "                   0.004438415190709082],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_optimizer': masked_array(data=['adamax', 'adamax', 'adamax', 'adamax', 'adamax'],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'activation': 'relu', 'batch_size': 59, 'learning_rate': 0.0027053511266219815, 'optimizer': 'adamax'}, {'activation': 'relu', 'batch_size': 44, 'learning_rate': 0.005944306073906301, 'optimizer': 'adamax'}, {'activation': 'relu', 'batch_size': 57, 'learning_rate': 0.006850703871388203, 'optimizer': 'adamax'}, {'activation': 'relu', 'batch_size': 60, 'learning_rate': 0.005978753744738821, 'optimizer': 'adamax'}, {'activation': 'relu', 'batch_size': 42, 'learning_rate': 0.004438415190709082, 'optimizer': 'adamax'}], 'split0_test_score': array([0.80464963, 0.79673674, 0.79795659, 0.80453991, 0.80834145]), 'split1_test_score': array([0.79514122, 0.80472582, 0.81429106, 0.79970439, 0.81379408]), 'split2_test_score': array([0.79968503, 0.80681055, 0.81968038, 0.81143182, 0.79791656]), 'mean_test_score': array([0.79982529, 0.8027577 , 0.81064268, 0.80522537, 0.80668403]), 'std_test_score': array([0.00388306, 0.0043417 , 0.0092363 , 0.00481217, 0.00658707]), 'rank_test_score': array([5, 4, 1, 3, 2])}\n"
     ]
    }
   ],
   "source": [
    "# show the best score we got from the models we ran above\n",
    "print(random_search.best_score_)\n",
    "# what versions of model did the randomsearch run\n",
    "print(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outcome\n",
    "The Random Search is picking the most consistantly progressive model based on accuracy. Even though the last model ended up at a better validation accuracy it lost accruacy more times than the 3rd model.   \n",
    "It had a mean test score of .81 where the last model had a mean test score of .806\n",
    "To be fair this is only running on 10 epochs so it is possible with more epochs the last model might out perform the 3rd model. \n",
    "It is also worth considering that the randomsearch only ran 15 models so their could be a more optimal model in the mix of all those models.  \n",
    "Running random search a few more times might get me a 95% or higher score if I had days to run a large number of random searches. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base line Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.4876\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "majority_class = np.argmax(np.bincount(label_train))\n",
    "baseline_predictions = np.full_like(label_test, fill_value=majority_class)\n",
    "baseline_accuracy = accuracy_score(label_test, baseline_predictions)\n",
    "\n",
    "print(f'Baseline Accuracy: {baseline_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows our 94% accuracy is way better than the baseline model which only give an accuracy of 48% trying to guess the majority class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this project, a robust neural network model was developed using TensorFlow's Keras Sequential architecture to predict tree species from a diverse set of environmental variables. The model demonstrated exceptional performance, achieving precision, recall, and F1-score values above 0.92 for key species like spruce and lodgepole pine. With an overall accuracy of 94%, the model showcased strong generalization capabilities across the dataset. While slightly lower performance was observed for certain species like cottonwood willow and aspen, the findings highlight the model's nuanced understanding of environmental features' relationships with tree species. This work not only contributes to the effective application of machine learning in environmental science but also suggests avenues for refinement and extension, positioning the model as a valuable tool for ecological studies and biodiversity conservation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
